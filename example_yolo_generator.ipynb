{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example YOLOv2 detector\n",
    "\n",
    "This notebook is the same as `example_yolo` except that it uses a `YoloGenerator` object for data augmentation. It allows to make transformation such as zoom, flips, rotations, ... and modify boxes accordingly (which is currently not supported by the dataset pipeline). \n",
    "\n",
    "However this makes the training 4 times slower so I suggest you to use it only if your dataset is really small. Otherwise, prefer to use the other notebook forfaster training (where there is also augmentation but only on colors / luminosity / contrasts and not on object position). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports + model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : 2.5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import plot, plot_multiple, set_display_options, limit_gpu_memory\n",
    "from datasets import get_dataset, prepare_dataset, test_dataset_time\n",
    "from models.detection import YOLO\n",
    "from custom_train_objects import YoloGenerator\n",
    "\n",
    "set_display_options()\n",
    "#limit_gpu_memory()\n",
    "\n",
    "input_size = 416\n",
    "model_name = 'yolo_test'\n",
    "print(\"Tensorflow version : {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'input_size' : input_size,\n",
    "    'backend'    : 'full_yolo',\n",
    "    'nb_class'   : 5,\n",
    "    'max_box_per_image' : 50,\n",
    "    'labels'     : ['face']\n",
    "}\n",
    "model = YOLO(nom = model_name, ** config)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model instanciation + dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(nom = model_name)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'sgd',\n",
    "    optimizer_config = {\n",
    "        'lr' : {'name' : 'WarmupScheduler', 'maxval' : 1e-3,'minval' : 1e-4, 'factor' : 1024, 'warmup_steps' : 1024}\n",
    "    },\n",
    "    loss_config = {'warmup_epochs' : 3}\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'wider'\n",
    "dataset = get_dataset(\n",
    "    dataset_name, max_box_per_image = model.max_box_per_image, box_as_dict = True\n",
    ")\n",
    "\n",
    "train, valid = dataset['train'], dataset['valid']\n",
    "print('Train size : {} - Valid size : {}'.format(len(train), len(valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(img):\n",
    "    return img / 255.\n",
    "\n",
    "config = {\n",
    "    'IMAGE_W' : input_size,\n",
    "    'IMAGE_H' : input_size,\n",
    "    'LABELS'  : model.labels,\n",
    "    'BOX'     : model.nb_box,\n",
    "    'ANCHORS' : model.anchors,\n",
    "    'GRID_W'  : model.grid_w,\n",
    "    'GRID_H'  : model.grid_h,\n",
    "    'TRUE_BOX_BUFFER' : model.max_box_per_image\n",
    "}\n",
    "train = YoloGenerator(train.sample(2048, random_state = 0), config, shuffle = True, norm = norm)\n",
    "valid = YoloGenerator(valid.sample(1024, random_state = 0), config, jitter = False, shuffle = False, norm = norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training + history analysis\n",
    "\n",
    "Note that augmentation is already done by the generator so you can remove default augmentation (`augment_prct = 0.`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 16\n",
    "\n",
    "train_size = None\n",
    "valid_size = None\n",
    "\n",
    "model.train(\n",
    "    train, validation_data = valid, train_times = 8,\n",
    "    train_size = train_size, valid_size = valid_size,\n",
    "    epochs = epochs, batch_size = batch_size,\n",
    "    augment_prct = 0., shuffle_size = 0, cache = False,\n",
    "    encode_fn = None, augment_fn = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.history)\n",
    "model.plot_history(ylim = (0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.predict(pd.DataFrame(train.images[:5]), save = False, debug = True, verbose = 3, obj_threshold = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.predict('lena.jpg', save = False, debug = True, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.stream(max_time = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = model.get_dataset_config(\n",
    "    is_validation = False, batch_size = 16, encode_fn = None, augment_fn = None, shuffle_size = 0)\n",
    "\n",
    "ds_train = prepare_dataset(train, ** config, debug = True)\n",
    "test_dataset_time(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.image import *\n",
    "\n",
    "config = model.get_dataset_config(is_validation = True, batch_size = 1, prefetch = False)\n",
    "\n",
    "ds_train = prepare_dataset(train.iloc[:5], ** config, debug = True)\n",
    "\n",
    "for _, data in train.iloc[:5].iterrows():\n",
    "    y_true, true_boxes = model.get_output(data)\n",
    "    image = model.get_input(data)\n",
    "    image = load_image(data['filename'])\n",
    "    boxes = [list(b) + [1, 0] for b in data['box'].astype(np.int32) if b[0] > 0]\n",
    "    print(np.array(boxes) / data['width'])\n",
    "    print(512 / (data['width'] * 13))\n",
    "    print(model.grid_w)\n",
    "    boxes = model.decode_output(y_true)\n",
    "    print(boxes)\n",
    "    plot(model.draw_prediction(image, boxes, labels = ['face', 'face']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
